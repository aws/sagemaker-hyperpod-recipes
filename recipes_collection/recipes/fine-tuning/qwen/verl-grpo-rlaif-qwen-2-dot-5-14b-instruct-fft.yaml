defaults:
  - /hydra_config/verl/default
  - /hydra_config/verl/algorithm/grpo
  - /hydra_config/verl/actor/default
  - /hydra_config/verl/ref/default
  - /hydra_config/verl/critic/default
  - /hydra_config/verl/rollout/vllm
  - /hydra_config/verl/actor_rollout_ref/default
  - /hydra_config/verl/trainer/default
  - /hydra_config/verl/data/default
  - /hydra_config/verl/reward_model/default
  - /hydra_config/verl/ray_cluster/default
  - /hydra_config/verl/peft/fft
  - /hydra_config/verl/reward/rlaif
  - /hydra_config/verl/model_config/qwen-2-5-14b-instruct
  - _self_

display_name: "Qwen 2.5 14B GRPO RLAIF Fine-Tuning"
version: "1.1.0"
instance_types: ["ml.p5.48xlarge"]

run:
  name: verl-grpo-qwen-2-dot-5-14b-instruct-fft

trainer:
  num_nodes: 1

training_config:
  actor_rollout_ref:
    actor:
      use_dynamic_bsz: false
      ppo_max_token_len_per_gpu: 16384
      fsdp_config:
        model_dtype: null
      optim:
        lr: 1.0e-05
    ref:
      log_prob_use_dynamic_bsz: false
      log_prob_micro_batch_size_per_gpu: 16
      log_prob_max_token_len_per_gpu: 16384
      fsdp_config:
        model_dtype: null
    rollout:
      prompt_length: 1024
      enforce_eager: true
      tensor_model_parallel_size: 2
      log_prob_use_dynamic_bsz: false
      log_prob_micro_batch_size_per_gpu: 16
      log_prob_max_token_len_per_gpu: 16384
      enable_chunked_prefill: true
      layered_summon: false
      merge_lora_for_inference: true
  trainer:
    total_epochs: 2
    experiment_name: phase_2
  data:
    max_prompt_length: 1024
    max_response_length: 4096
    val_batch_size: null
  critic:
    rollout_n: 6
    ppo_max_token_len_per_gpu: 32768
    use_dynamic_bsz: false
    model:
      path: deepseek-ai/deepseek-llm-7b-chat/
    checkpoint:
      save_contents:
      - model
      - optimizer
      - extra
      load_contents:
      - model
      - optimizer
      - extra
  reward_model:
    use_dynamic_bsz: false
    model:
      path: sfairXC/FsfairX-LLaMA3-RM-v0.1/
    reward_kwargs:
      reward_fn_name: llmj
      kwargs:
        llmj_prompt_template_path: /opt/ml/code/verl/summarize.jinja
        model_id: bedrock/deepseek.v3-v1:0
        num_retries: 5
        range:
        - 0.0
        - 1.0
        sampling_params:
          top_p: 0.9
          temperature: 0.0
          max_completion_tokens: 2048
          reasoning_effort: null
        max_workers: 100
        aws_region_name: null
  custom_reward_function:
    path: ''
    name: ''
